/**
 * This enum defines all the different types of tokens that our language recognizes.
 * A token is the smallest unit of code that has meaning, like a number, an operator,
 * or a keyword.
 */
export enum TokenType {
    // Literals: represent raw data values in the code.
    Number,      // e.g., 123, 45.67
    String,      // e.g., "hello"
    Identifier,  // e.g., my_variable
    Boolean,     // true or false

    // Keywords: words with special meaning in the language.
    If,          // å¦‚æœ
    ElseIf,      // ä¹Ÿå¯èƒ½
    Else,        // ä¸ç„¶å°±
    True,        // çœŸçš„
    False,       // å‡çš„
    Var,         // è·Ÿä½ èªª

    // Operators: symbols that perform operations on data.
    Plus,          // åŠ ä¸Š
    Minus,         // æ¸›æ‰
    Asterisk,      // ä¹˜
    Slash,         // é™¤
    Percent,       // å–é¤˜æ•¸
    Equal,         // æ˜¯
    EqualEqual,    // ç­‰æ–¼
    Bang,          // âŒ
    BangEqual,     // âŒç­‰æ–¼
    Less,          // å°æ–¼
    LessEqual,     // å°æ–¼ç­‰æ–¼
    Greater,       // å¤§æ–¼
    GreaterEqual,  // å¤§æ–¼ç­‰æ–¼
    And,           // è€Œä¸”
    Or,            // æˆ–æ˜¯

    // Punctuation: characters that structure the code.
    LeftParen,     // ğŸ‘‰
    RightParen,    // ğŸ‘ˆ
    LeftBrace,     // ğŸ‘†
    RightBrace,    // ğŸ‘‡
    LeftBracket,   // ğŸ¤œ
    RightBracket,  // ğŸ¤›
    Comma,         // ğŸŒŸ
    Semicolon,     // ğŸ’¦
    Print,         // ğŸ¥°
    Greet,         // â¤...â¤

    // End of File: a special token to mark the end of the source code.
    EOF,
}

/**
 * This interface defines the structure of a Token. Each token has a type,
 * the original text from the source code (lexeme), an optional literal value
 * (for numbers, strings, etc.), and the line number where it appeared, which
 * is useful for error reporting.
 */
export interface Token {
    type: TokenType;
    lexeme: string;
    literal?: any;
    line: number;
}

/**
 * The Lexer (or scanner) is responsible for taking the raw source code as a string
 * and breaking it down into a series of tokens.
 */
export class Lexer {
    private source: string;
    private tokens: Token[] = [];
    private start = 0;
    private current = 0;
    private line = 1;

    /**
     * A map of all the keywords in the language and their corresponding token types.
     */
    private static readonly keywords: { [key: string]: TokenType } = {
        "å¦‚æœ": TokenType.If,
        "ä¹Ÿå¯èƒ½": TokenType.ElseIf,
        "ä¸ç„¶å°±": TokenType.Else,
        "çœŸçš„": TokenType.True,
        "å‡çš„": TokenType.False,
        "æ˜¯": TokenType.Equal,
        "ç­‰æ–¼": TokenType.EqualEqual,
        "âŒç­‰æ–¼": TokenType.BangEqual,
        "å°æ–¼": TokenType.Less,
        "å¤§æ–¼": TokenType.Greater,
        "å°æ–¼ç­‰æ–¼": TokenType.LessEqual,
        "å¤§æ–¼ç­‰æ–¼": TokenType.GreaterEqual,
        "è€Œä¸”": TokenType.And,
        "æˆ–æ˜¯": TokenType.Or,
        "åŠ ä¸Š": TokenType.Plus,
        "æ¸›æ‰": TokenType.Minus,
        "ä¹˜": TokenType.Asterisk,
        "é™¤": TokenType.Slash,
        "å–é¤˜æ•¸": TokenType.Percent,
        "è·Ÿä½ èªª": TokenType.Var,
    };

    /**
     * A map of all the single-character/emoji tokens in the language.
     * This makes it easy to add new emoji tokens in the future.
     */
    private static readonly emojiTokens: { [key: string]: TokenType } = {
        'ğŸ‘‰': TokenType.LeftParen,
        'ğŸ‘ˆ': TokenType.RightParen,
        'ğŸ‘†': TokenType.LeftBrace,
        'ğŸ‘‡': TokenType.RightBrace,
        'ğŸ¤œ': TokenType.LeftBracket,
        'ğŸ¤›': TokenType.RightBracket,
        'ğŸŒŸ': TokenType.Comma,
        'ğŸ’¦': TokenType.Semicolon,
        'ğŸ¥°': TokenType.Print,
        'âŒ': TokenType.Bang,
    };

    private static readonly greetingParens = ['â¤', 'ğŸ˜˜', 'ğŸ¥º', 'ğŸ˜ˆ', 'ğŸ˜¥', 'ğŸ’'];

    // A combined list of all multi-character symbols to prevent them from being parsed as identifiers.
    private static readonly specialSymbols = [
        ...Object.keys(Lexer.emojiTokens),
        ...Lexer.greetingParens,
        'ğŸ¤—',
        ' ', '\r', '\t', '\n', '\0'
    ];

    constructor(source: string) {
        this.source = source;
    }

    /**
     * This is the main method of the lexer. It scans the source code character
     * by character and generates a list of tokens.
     * @returns An array of tokens.
     */
    scanTokens(): Token[] {
        while (!this.isAtEnd()) {
            // We are at the beginning of the next lexeme.
            this.start = this.current;
            this.scanToken();
        }

        // Add a final "end of file" token to mark the end of the code.
        this.tokens.push({ type: TokenType.EOF, lexeme: "", line: this.line });
        return this.tokens;
    }

    /**
     * Checks if we have consumed all the characters in the source code.
     */
    private isAtEnd(): boolean {
        return this.current >= this.source.length;
    }

    /**
     * Scans a single token from the source code.
     */
    private scanToken(): void {
        this.skipWhitespace();
        this.start = this.current;

        if (this.isAtEnd()) return;

        const remaining = this.source.substring(this.current);

        // Priority 1: Greetings (e.g., â¤...â¤)
        for (const paren of Lexer.greetingParens) {
            if (remaining.startsWith(paren)) {
                this.greeting(paren);
                return;
            }
        }

        // Priority 2: Strings (e.g., ğŸ¤—...ğŸ¤—)
        if (remaining.startsWith('ğŸ¤—')) {
            this.string();
            return;
        }

        // Priority 3: Multi-character keywords (must be checked before single emoji tokens)
        // Check keywords that might start with emoji characters
        for (const keyword in Lexer.keywords) {
            if (remaining.startsWith(keyword)) {
                this.current += keyword.length;
                this.addToken(Lexer.keywords[keyword]);
                return;
            }
        }

        // Priority 4: Single emoji tokens (e.g., ğŸ‘‰, ğŸ’¦, ğŸ¥°, âŒ)
        for (const lexeme in Lexer.emojiTokens) {
            if (remaining.startsWith(lexeme)) {
                this.current += lexeme.length;
                this.addToken(Lexer.emojiTokens[lexeme]);
                return;
            }
        }

        const c = this.peek();
        // Priority 5: Numbers
        if (this.isDigit(c)) {
            this.number();
            return;
        }

        // Priority 6: Identifiers and keywords
        if (this.isAlpha(c)) {
            this.identifier();
            return;
        }

        // If we've gotten this far, we don't know what this character is.
        // In a real compiler, we'd report an error. Here, we'll just consume
        // it to prevent an infinite loop.
        this.advance();
    }

    private skipWhitespace(): void {
        while (true) {
            const c = this.peek();
            switch (c) {
                case ' ':
                case '\r':
                case '\t':
                    this.advance();
                    break;
                case '\n':
                    this.line++;
                    this.advance();
                    break;
                default:
                    return;
            }
        }
    }

    /**
     * Consumes the current character in the source and returns it.
     */
    private advance(): string {
        return this.source.charAt(this.current++);
    }

    /**
     * Creates a new token for the current lexeme.
     * @param type The type of the token.
     * @param literal The literal value of the token (optional).
     */
    private addToken(type: TokenType, literal?: any): void {
        const text = this.source.substring(this.start, this.current);
        this.tokens.push({ type, lexeme: text, literal, line: this.line });
    }

    /**
     * Checks if the current character matches the expected character. If it does,
     * it consumes the character and returns true. Otherwise, it returns false.
     * @param expected The character to match.
     */
    private match(expected: string): boolean {
        if (this.isAtEnd()) return false;
        if (this.source.charAt(this.current) !== expected) return false;

        this.current++;
        return true;
    }

    /**
     * Looks at the current character without consuming it.
     */
    private peek(): string {
        if (this.isAtEnd()) return '\0';
        return this.source.charAt(this.current);
    }

    private greeting(paren: string): void {
        // Consume the opening paren
        this.current += paren.length;

        // Look for any greeting paren as the closing delimiter
        while (!this.isAtEnd()) {
            const remaining = this.source.substring(this.current);
            let foundClosing = false;
            
            for (const closingParen of Lexer.greetingParens) {
                if (remaining.startsWith(closingParen)) {
                    foundClosing = true;
                    // The value between the parens
                    const value = this.source.substring(this.start + paren.length, this.current);
                    
                    // Consume the closing paren
                    this.current += closingParen.length;
                    
                    this.addToken(TokenType.Greet, value);
                    return;
                }
            }
            
            if (!foundClosing) {
                if (this.peek() === '\n') this.line++;
                this.advance();
            }
        }

        // Unterminated greeting - reached end of file
    }

    /**
     * Scans a string literal.
     */
    private string(): void {
        // Consume the opening 'ğŸ¤—'
        this.current += 'ğŸ¤—'.length;

        while (!this.isAtEnd() && !this.source.substring(this.current).startsWith('ğŸ¤—')) {
            if (this.peek() === '\n') this.line++;
            this.advance();
        }

        if (this.isAtEnd()) {
            // Unterminated string.
            return;
        }

        // The closing 'ğŸ¤—'.
        const value = this.source.substring(this.start + 'ğŸ¤—'.length, this.current);
        
        // Consume the closing 'ğŸ¤—'
        this.current += 'ğŸ¤—'.length;
        
        this.addToken(TokenType.String, value);
    }

    /**
     * Checks if a character is a digit.
     */
    private isDigit(c: string): boolean {
        return c >= '0' && c <= '9';
    }

    /**
     * Scans a number literal.
     */
    private number(): void {
        while (this.isDigit(this.peek())) this.advance();

        // Look for a fractional part.
        if (this.peek() === '.' && this.isDigit(this.peekNext())) {
            // Consume the "."
            this.advance();

            while (this.isDigit(this.peek())) this.advance();
        }

        this.addToken(TokenType.Number, parseFloat(this.source.substring(this.start, this.current)));
    }

    /**
     * Looks at the character after the current one without consuming it.
     */
    private peekNext(): string {
        if (this.current + 1 >= this.source.length) return '\0';
        return this.source.charAt(this.current + 1);
    }

    /**
     * Scans an identifier or a keyword.
     */
    private identifier(): void {
        while (this.isAlphaNumeric(this.peek())) this.advance();

        const text = this.source.substring(this.start, this.current);
        let type = Lexer.keywords[text];
        if (type === undefined) type = TokenType.Identifier;
        this.addToken(type);
    }

    /**
     * Checks if a character is a valid start for an identifier.
     * In "Uncle Lang", this is any character that is not a digit and not
     * a special symbol used for other tokens.
     */
    private isAlpha(c: string): boolean {
        const specialChars = "ğŸ‘‰ğŸ‘ˆğŸ‘†ğŸ‘‡ğŸ¤œğŸ¤›ğŸŒŸğŸ¥°âŒğŸ¤—â¤ğŸ˜˜ğŸ¥ºğŸ˜ˆğŸ˜¥ğŸ’ğŸ’¦ \r\t\n";
        return c !== '\0' && !this.isDigit(c) && !specialChars.includes(c);
    }

    /**
     * Checks if a character can be part of an identifier.
     */
    private isAlphaNumeric(c: string): boolean {
        return this.isAlpha(c) || this.isDigit(c);
    }
}
